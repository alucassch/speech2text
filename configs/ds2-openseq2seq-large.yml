random_seed: 42
numpy_seed: 42
pytorch_seed: 42

alphabet: 
  from_file: &alphabet $CODE_DIR/data/labels.en.json 

transforms: &transforms
  type: compose
  transforms:
    - type: to-tensor
      sample_rate: 16000
    - type: to-spectrogram

target_transforms: &target_transforms
  type: to-label
  locale: en
  alphabet: *alphabet

dataset_reader: &dataset_reader
  type: audio-dataset
  data_dir: $DATA_DIR
  transforms: *transforms
  target_transforms: *target_transforms

train_dataset:
  <<: *dataset_reader
  manifest_filepath: $CODE_DIR/data/librispeech.train.csv
  transforms:
    type: compose
    transforms:
      - type: to-tensor
        sample_rate: 16000
        augment: True
      - type: to-spectrogram

val_dataset:
  <<: *dataset_reader
  manifest_filepath: $CODE_DIR/data/librispeech.val.csv

data_loader: audio-loader

model:
  type: ds2
  conv_layers:
    - kernel_size: [41, 11]
      stride: [2, 2]
      out_channels: 32
      padding: [20, 5]
    - kernel_size: [21, 11]
      stride: [2, 1]
      out_channels: 32
      padding: [10, 5]

  rnn_type: gru
  rnn_hidden_size: 800
  num_rnn_layers: 5
  hidden_size: 1600
  bidirectional: True

  dropout: 0.5

loss:
  type: ctc

trainer:
  num_epochs: 100
  batch_size: 16
  warmup_epochs: 5
  # label_smoothing: 0.0
  # larc_eta: 0.001

  # allow list of regex
  # no_grad:

  optimizer:
    type: sgd
    lr: 0.001
    momentum: 0.90
    nesterov: True
    weight_decay: 0.0005

  lr_scheduler:
    type: exponential
    gamma: 0.9090909090909

  clip_grad_norm: 400
  clip_grad_value: null

  metrics: [wer, cer]
  monitor: wer


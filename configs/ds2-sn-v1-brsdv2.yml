# DeepSpeech 2 by SeanNaren for BRSDv1 dataset
alphabet: 
  from_file: &alphabet $CODE_DIR/data/labels.pt-BR.json 

transforms: &transforms
  type: compose
  transforms:
    - type: to-tensor
      sample_rate: 16000
    - type: to-spectrogram

target_transforms: &target_transforms
  type: to-label
  locale: pt-BR
  alphabet: *alphabet
  convert_number_to_words: True
  filter_if_not_in_alphabet: True

dataset_reader: &dataset_reader
  type: audio-dataset
  data_dir: $DATA_DIR
  transforms: *transforms
  target_transforms: *target_transforms

train_dataset:
  <<: *dataset_reader
  manifest_filepath: $CODE_DIR/data/pt_BR.extended.train.csv
  transforms:
    type: compose
    transforms:
      - type: to-tensor
        augment: True
      - type: to-spectrogram

val_dataset:
  <<: *dataset_reader
  manifest_filepath: $CODE_DIR/data/lapsbm.val.csv

data_loader: audio-loader

model:
  type: ds2-seannaren
  rnn_type: gru
  rnn_hidden_size: 800
  num_rnn_layers: 5
  bidirectional: True

loss:
  type: ctc

trainer:
  num_epochs: 100
  batch_size: 32
  # warmup_epochs: 1

  # label_smoothing: 0.0

  
  # no_grad: [] # if regex match, will set require_grad to false
  no_ft:
  - fc.0.module.1.* # list with weights name to ignore when loading a pretrained model

  optimizer:
    type: sgd
    lr: 0.00048
    momentum: 0.90
    nesterov: True
    weight_decay: 0.00001
    # scale: True # if true, lr will be scaled by the world size
    # larc_eta: 0.001

  lr_scheduler:
   type: exponential
   gamma: 0.99
    # type: cosine
    # T_max: 20
    # eta_min: 0.00001

  clip_grad_norm: 400
  clip_grad_value: null

  metrics: [wer, cer]
  monitor: wer
